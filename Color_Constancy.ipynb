{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_file_list1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shade_of_gray_cc(img, power=6, gamma=None):\n",
    "    \"\"\"\n",
    "    img (numpy array): the original image with format of (h, w, c)\n",
    "    power (int): the degree of norm, 6 is used in reference paper\n",
    "    gamma (float): the value of gamma correction, 2.2 is used in reference paper\n",
    "    \"\"\"\n",
    "    img_dtype = img.dtype\n",
    "\n",
    "    if gamma is not None:\n",
    "        img = img.astype('uint8')\n",
    "        look_up_table = np.ones((256,1), dtype='uint8') * 0\n",
    "        for i in range(256):\n",
    "            look_up_table[i][0] = 255 * pow(i/255, 1/gamma)\n",
    "        img = cv2.LUT(img, look_up_table)\n",
    "\n",
    "    img = img.astype('float32')\n",
    "    img_power = np.power(img, power)\n",
    "    rgb_vec = np.power(np.mean(img_power, (0,1)), 1/power)\n",
    "    rgb_norm = np.sqrt(np.sum(np.power(rgb_vec, 2.0)))\n",
    "    rgb_vec = rgb_vec/rgb_norm\n",
    "    rgb_vec = 1/(rgb_vec*np.sqrt(3))\n",
    "    img = np.multiply(img, rgb_vec)\n",
    "\n",
    "    # Andrew Anikin suggestion\n",
    "    img = np.clip(img, a_min=0, a_max=255)\n",
    "    \n",
    "    return img.astype(img_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in os.listdir('Skin_data/Original data/Hair_Removed_Test_Data/'):\n",
    "        img_file_list1.append((os.path.join('Skin_data/Original data/Hair_Removed_Test_Data/', fname)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_cc (resize=None):\n",
    "    \n",
    "    for f1 in img_file_list1:\n",
    "        src = cv2.imread(f1)\n",
    "        \n",
    "        if resize is not None:\n",
    "            img = cv2.resize(src, resize, cv2.INTER_AREA)\n",
    "            \n",
    "        cc_img = shade_of_gray_cc (img)\n",
    "        \n",
    "        fname1 = os.path.splitext(os.path.basename(f1))[0]\n",
    "        output_fname = os.path.join('Skin_data/Original data/Color_Fixed_Test_Data/', '{}.jpg'.format(fname1))\n",
    "        cv2.imwrite(output_fname, cc_img)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_cc ((256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import datetime\n",
    "import scipy as sp\n",
    "import sys\n",
    "import keras as keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Activation, Conv2D, MaxPooling2D, UpSampling2D, Dropout\n",
    "from keras.layers.merge import concatenate\n",
    "from keras import backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFPDMNet(patchHeight, patchWidth, ipCh, outCh):\n",
    "\n",
    "    # Input\n",
    "    input1 = Input((patchHeight, patchWidth, ipCh))\n",
    "\n",
    "    # Encoder\n",
    "    conv1 = Conv2D(16, (3, 3), padding='same')(input1)\n",
    "    conv1 = tf.keras.layers.BatchNormalization()(conv1)\n",
    "    conv1 = Activation('relu')(conv1)\n",
    "    conv1 = Dropout(0.2)(conv1)\n",
    "\n",
    "    conv1 = concatenate([input1, conv1], axis=-1)\n",
    "    conv1 = Conv2D(16, (3, 3), padding='same')(conv1)\n",
    "    conv1 = tf.keras.layers.BatchNormalization()(conv1)\n",
    "    conv1 = Activation('relu')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    #\n",
    "    input2 = MaxPooling2D(pool_size=(2, 2))(input1)\n",
    "    conv21 = concatenate([input2, pool1], axis=-1)\n",
    "\n",
    "    conv2 = Conv2D(32, (3, 3), padding='same')(conv21)\n",
    "    conv2 = tf.keras.layers.BatchNormalization()(conv2)\n",
    "    conv2 = Activation('relu')(conv2)\n",
    "    conv2 = Dropout(0.2)(conv2)\n",
    "\n",
    "    conv2 = concatenate([conv21, conv2], axis=-1)\n",
    "    conv2 = Conv2D(32, (3, 3), padding='same')(conv2)\n",
    "    conv2 = tf.keras.layers.BatchNormalization()(conv2)\n",
    "    conv2 = Activation('relu')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    #\n",
    "    input3 = MaxPooling2D(pool_size=(2, 2))(input2)\n",
    "    conv31 = concatenate([input3, pool2], axis=-1)\n",
    "\n",
    "    conv3 = Conv2D(64, (3, 3), padding='same')(conv31)\n",
    "    conv3 = tf.keras.layers.BatchNormalization()(conv3)\n",
    "    conv3 = Activation('relu')(conv3)\n",
    "    conv3 = Dropout(0.2)(conv3)\n",
    "    \n",
    "    conv3 = concatenate([conv31, conv3], axis=-1)\n",
    "    conv3 = Conv2D(64, (3, 3), padding='same')(conv3)\n",
    "    conv3 = tf.keras.layers.BatchNormalization()(conv3)\n",
    "    conv3 = Activation('relu')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    #\n",
    "    input4 = MaxPooling2D(pool_size=(2, 2))(input3)\n",
    "    conv41 = concatenate([input4, pool3], axis=-1)\n",
    "\n",
    "    conv4 = Conv2D(128, (3, 3), padding='same')(conv41)\n",
    "    conv4 = tf.keras.layers.BatchNormalization()(conv4)\n",
    "    conv4 = Activation('relu')(conv4)\n",
    "    conv4 = Dropout(0.2)(conv4)\n",
    "    \n",
    "    conv4 = concatenate([conv41, conv4], axis=-1)\n",
    "    conv4 = Conv2D(128, (3, 3), padding='same')(conv4)\n",
    "    conv4 = tf.keras.layers.BatchNormalization()(conv4)\n",
    "    conv4 = Activation('relu')(conv4)\n",
    "    conv4 = Dropout(0.2)(conv4)\n",
    "\n",
    "    conv4 = Conv2D(128, (3, 3), padding='same')(conv4)\n",
    "    conv4 = tf.keras.layers.BatchNormalization()(conv4)\n",
    "    conv4 = Activation('relu')(conv4)\n",
    "\n",
    "    # Decoder\n",
    "    conv5 = UpSampling2D(size=(2, 2))(conv4)\n",
    "    conv51 = concatenate([conv3, conv5], axis=-1)\n",
    "\n",
    "    conv5 = Conv2D(64, (3, 3), padding='same')(conv51)\n",
    "    conv5 = tf.keras.layers.BatchNormalization()(conv5)\n",
    "    conv5 = Activation('relu')(conv5)\n",
    "    conv5 = Dropout(0.2)(conv5)\n",
    "    \n",
    "    conv5 = concatenate([conv51, conv5], axis=-1)\n",
    "    conv5 = Conv2D(64, (3, 3), padding='same')(conv5)\n",
    "    conv5 = tf.keras.layers.BatchNormalization()(conv5)\n",
    "    conv5 = Activation('relu')(conv5)\n",
    "\n",
    "    #\n",
    "    conv6 = UpSampling2D(size=(2, 2))(conv5)\n",
    "    conv61 = concatenate([conv2, conv6], axis=-1)\n",
    "\n",
    "    conv6 = Conv2D(32, (3, 3), padding='same')(conv61)\n",
    "    conv6 = tf.keras.layers.BatchNormalization()(conv6)\n",
    "    conv6 = Activation('relu')(conv6)\n",
    "    conv6 = Dropout(0.2)(conv6)\n",
    "    \n",
    "    conv6 = concatenate([conv61, conv6], axis=-1)\n",
    "    conv6 = Conv2D(32, (3, 3), padding='same')(conv6)\n",
    "    conv6 = tf.keras.layers.BatchNormalization()(conv6)\n",
    "    conv6 = Activation('relu')(conv6)\n",
    "\n",
    "    #\n",
    "    conv7 = UpSampling2D(size=(2, 2))(conv6)\n",
    "    conv71 = concatenate([conv1, conv7], axis=-1)\n",
    "\n",
    "    conv7 = Conv2D(16, (3, 3), padding='same')(conv71)\n",
    "    conv7 = tf.keras.layers.BatchNormalization()(conv7)\n",
    "    conv7 = Activation('relu')(conv7)\n",
    "    conv7 = Dropout(0.2)(conv7)\n",
    "    \n",
    "    conv7 = concatenate([conv71, conv7], axis=-1)\n",
    "    conv7 = Conv2D(16, (3, 3), padding='same')(conv7)\n",
    "    conv7 = tf.keras.layers.BatchNormalization()(conv7)\n",
    "    conv7 = Activation('relu')(conv7)\n",
    "\n",
    "    # Final\n",
    "    conv81 = UpSampling2D(size=(8, 8))(conv4)\n",
    "    conv82 = UpSampling2D(size=(4, 4))(conv5)\n",
    "    conv83 = UpSampling2D(size=(2, 2))(conv6)\n",
    "    conv8 = concatenate([conv81, conv82, conv83, conv7], axis=-1)\n",
    "    conv8 = Conv2D(outCh, (1, 1), activation='sigmoid')(conv8)\n",
    "\n",
    "    ############\n",
    "    model = Model(inputs=input1, outputs=conv8)\n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_45), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'batch_normalization_45/gamma:0' shape=(16,) dtype=float32>\n",
      "  <tf.Variable 'batch_normalization_45/beta:0' shape=(16,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_46), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'batch_normalization_46/gamma:0' shape=(16,) dtype=float32>\n",
      "  <tf.Variable 'batch_normalization_46/beta:0' shape=(16,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_47), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'batch_normalization_47/gamma:0' shape=(32,) dtype=float32>\n",
      "  <tf.Variable 'batch_normalization_47/beta:0' shape=(32,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_48), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'batch_normalization_48/gamma:0' shape=(32,) dtype=float32>\n",
      "  <tf.Variable 'batch_normalization_48/beta:0' shape=(32,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_49), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'batch_normalization_49/gamma:0' shape=(64,) dtype=float32>\n",
      "  <tf.Variable 'batch_normalization_49/beta:0' shape=(64,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_50), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'batch_normalization_50/gamma:0' shape=(64,) dtype=float32>\n",
      "  <tf.Variable 'batch_normalization_50/beta:0' shape=(64,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_51), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'batch_normalization_51/gamma:0' shape=(128,) dtype=float32>\n",
      "  <tf.Variable 'batch_normalization_51/beta:0' shape=(128,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_52), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'batch_normalization_52/gamma:0' shape=(128,) dtype=float32>\n",
      "  <tf.Variable 'batch_normalization_52/beta:0' shape=(128,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_53), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'batch_normalization_53/gamma:0' shape=(128,) dtype=float32>\n",
      "  <tf.Variable 'batch_normalization_53/beta:0' shape=(128,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_54), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'batch_normalization_54/gamma:0' shape=(64,) dtype=float32>\n",
      "  <tf.Variable 'batch_normalization_54/beta:0' shape=(64,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_55), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'batch_normalization_55/gamma:0' shape=(64,) dtype=float32>\n",
      "  <tf.Variable 'batch_normalization_55/beta:0' shape=(64,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_56), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'batch_normalization_56/gamma:0' shape=(32,) dtype=float32>\n",
      "  <tf.Variable 'batch_normalization_56/beta:0' shape=(32,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_57), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'batch_normalization_57/gamma:0' shape=(32,) dtype=float32>\n",
      "  <tf.Variable 'batch_normalization_57/beta:0' shape=(32,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_58), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'batch_normalization_58/gamma:0' shape=(16,) dtype=float32>\n",
      "  <tf.Variable 'batch_normalization_58/beta:0' shape=(16,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_59), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'batch_normalization_59/gamma:0' shape=(16,) dtype=float32>\n",
      "  <tf.Variable 'batch_normalization_59/beta:0' shape=(16,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'torch.Size' object has no attribute 'as_list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-357bd20f608d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mfpDenNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\Tkeras\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    986\u001b[0m         training=training_mode):\n\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 988\u001b[1;33m       \u001b[0minput_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    989\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0meager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    990\u001b[0m         \u001b[0mcall_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tkeras\\lib\\site-packages\\keras\\engine\\input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    267\u001b[0m                              \u001b[1;34m' is incompatible with layer '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlayer_name\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m                              \u001b[1;34m': expected shape='\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 269\u001b[1;33m                              ', found shape=' + display_shape(x.shape))\n\u001b[0m\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tkeras\\lib\\site-packages\\keras\\engine\\input_spec.py\u001b[0m in \u001b[0;36mdisplay_shape\u001b[1;34m(shape)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdisplay_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 273\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'torch.Size' object has no attribute 'as_list'"
     ]
    }
   ],
   "source": [
    "fpDenNet = getFPDMNet(64, 64, 3, 3)\n",
    "import torch\n",
    "\n",
    "x = torch.randn((1, 3, 64,64))\n",
    "fpDenNet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = Input((64, 64, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 64, 64, 3])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
